{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37447ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D,AveragePooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15153e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=pd.read_csv(r\"C:\\Users\\dhanu\\Desktop\\Mini Project\\code_new\\five.csv\")\n",
    "#1 zcr\n",
    "#2 to 11 chroma stft\n",
    "# 12 to 32 mfcc\n",
    "#33 rms\n",
    "# rest mel\n",
    "\n",
    "X = d.iloc[: ,:-1].values\n",
    "Y = d['label'].values\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed9d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_zcr,x_train_chroma_stft,x_train_mfcc,x_train_rms,x_train_mel=[],[],[],[],[]\n",
    "x_test_zcr,x_test_chroma_stft,x_test_mfcc,x_test_rms,x_test_mel=[],[],[],[],[]\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    x_train_zcr.append([x_train[i][0]])\n",
    "    x_train_chroma_stft.append(x_train[i][1:12])\n",
    "    x_train_mfcc.append(x_train[i][12:33])\n",
    "    x_train_rms.append([x_train[i][33]])\n",
    "    x_train_mel.append(x_train[i][34:])\n",
    "for i in range(len(x_test)):  \n",
    "    x_test_zcr.append([x_test[i][0]])\n",
    "    x_test_chroma_stft.append(x_test[i][1:12])\n",
    "    x_test_mfcc.append(x_test[i][12:33])\n",
    "    x_test_rms.append([x_test[i][33]])\n",
    "    x_test_mel.append(x_test[i][34:])\n",
    "x_train_zcr,x_train_chroma_stft,x_train_mfcc,x_train_rms,x_train_mel=np.array(x_train_zcr),np.array(x_train_chroma_stft),np.array(x_train_mfcc),np.array(x_train_rms),np.array(x_train_mel)\n",
    "x_test_zcr,x_test_chroma_stft,x_test_mfcc,x_test_rms,x_test_mel=np.array(x_test_zcr),np.array(x_test_chroma_stft),np.array(x_test_mfcc),np.array(x_test_rms),np.array(x_test_mel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07031b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 162, 256)          1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 81, 256)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 81, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 41, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 41, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 21, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 128)           0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 21, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 11, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 704)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                22560     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 557,189\n",
      "Trainable params: 557,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "226/226 [==============================] - 12s 46ms/step - loss: 1.4773 - accuracy: 0.3362 - val_loss: 1.4411 - val_accuracy: 0.3494 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 1.3388 - accuracy: 0.4178 - val_loss: 1.2268 - val_accuracy: 0.5058 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 1.2356 - accuracy: 0.4662 - val_loss: 1.1732 - val_accuracy: 0.4925 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 1.1969 - accuracy: 0.4923 - val_loss: 1.1281 - val_accuracy: 0.5287 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 1.1339 - accuracy: 0.5228 - val_loss: 1.1043 - val_accuracy: 0.5403 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 1.1071 - accuracy: 0.5321 - val_loss: 1.0744 - val_accuracy: 0.5478 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 1.0728 - accuracy: 0.5450 - val_loss: 1.0799 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 1.0606 - accuracy: 0.5505 - val_loss: 1.0418 - val_accuracy: 0.5487 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 1.0412 - accuracy: 0.5640 - val_loss: 1.0179 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 1.0302 - accuracy: 0.5669 - val_loss: 1.0219 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 1.0080 - accuracy: 0.5759 - val_loss: 1.0406 - val_accuracy: 0.5545 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.9936 - accuracy: 0.5804 - val_loss: 1.0103 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.9869 - accuracy: 0.5923 - val_loss: 1.0169 - val_accuracy: 0.5749 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.9670 - accuracy: 0.5966 - val_loss: 1.0387 - val_accuracy: 0.5599 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.9617 - accuracy: 0.6010 - val_loss: 0.9936 - val_accuracy: 0.5707 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "226/226 [==============================] - 11s 49ms/step - loss: 0.9352 - accuracy: 0.6117 - val_loss: 1.0474 - val_accuracy: 0.5782 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.9144 - accuracy: 0.6182 - val_loss: 1.0235 - val_accuracy: 0.5728 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.9074 - accuracy: 0.6261 - val_loss: 1.0318 - val_accuracy: 0.5715 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.8907 - accuracy: 0.6375 - val_loss: 0.9970 - val_accuracy: 0.5944 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.8677 - accuracy: 0.6453 - val_loss: 1.0094 - val_accuracy: 0.5749 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.8608 - accuracy: 0.6536 - val_loss: 0.9881 - val_accuracy: 0.5865 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.8551 - accuracy: 0.6551 - val_loss: 1.0432 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.8284 - accuracy: 0.6637 - val_loss: 1.0214 - val_accuracy: 0.5836 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.8171 - accuracy: 0.6701 - val_loss: 1.0283 - val_accuracy: 0.5832 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.8011 - accuracy: 0.6702 - val_loss: 1.0214 - val_accuracy: 0.5765 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.7831 - accuracy: 0.6845 - val_loss: 1.1200 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.7527 - accuracy: 0.6924 - val_loss: 1.0507 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.7543 - accuracy: 0.6980 - val_loss: 1.0449 - val_accuracy: 0.5857 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.7381 - accuracy: 0.7035 - val_loss: 1.0778 - val_accuracy: 0.5824 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.7138 - accuracy: 0.7145 - val_loss: 1.1164 - val_accuracy: 0.5882 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.7223 - accuracy: 0.7153 - val_loss: 1.0569 - val_accuracy: 0.5899 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.6873 - accuracy: 0.7226 - val_loss: 1.1071 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.6806 - accuracy: 0.7261 - val_loss: 1.1258 - val_accuracy: 0.5765 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.6484 - accuracy: 0.7440 - val_loss: 1.1557 - val_accuracy: 0.5928 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.6654 - accuracy: 0.7362 - val_loss: 1.1424 - val_accuracy: 0.5828 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.6359 - accuracy: 0.7477 - val_loss: 1.2299 - val_accuracy: 0.5661 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.6200 - accuracy: 0.7573 - val_loss: 1.1809 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.6139 - accuracy: 0.7554 - val_loss: 1.2995 - val_accuracy: 0.5678 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.6049 - accuracy: 0.7604 - val_loss: 1.2593 - val_accuracy: 0.5765 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.5881 - accuracy: 0.7692 - val_loss: 1.3013 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.5662 - accuracy: 0.7780 - val_loss: 1.2346 - val_accuracy: 0.5778 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.5581 - accuracy: 0.7802 - val_loss: 1.3197 - val_accuracy: 0.5799 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.5726 - accuracy: 0.7762 - val_loss: 1.2706 - val_accuracy: 0.5899 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.5320 - accuracy: 0.7938 - val_loss: 1.3090 - val_accuracy: 0.5853 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "226/226 [==============================] - 10s 43ms/step - loss: 0.5328 - accuracy: 0.7928 - val_loss: 1.3732 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "226/226 [==============================] - 10s 43ms/step - loss: 0.5192 - accuracy: 0.7967 - val_loss: 1.3052 - val_accuracy: 0.5819 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "226/226 [==============================] - 10s 43ms/step - loss: 0.5042 - accuracy: 0.8054 - val_loss: 1.3460 - val_accuracy: 0.5645 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.4828 - accuracy: 0.8114 - val_loss: 1.4888 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.4804 - accuracy: 0.8125 - val_loss: 1.4292 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.4749 - accuracy: 0.8168 - val_loss: 1.4825 - val_accuracy: 0.5711 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.4512 - accuracy: 0.8219 - val_loss: 1.5004 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.4437 - accuracy: 0.8316 - val_loss: 1.4164 - val_accuracy: 0.5899 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.4457 - accuracy: 0.8286 - val_loss: 1.3755 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.4337 - accuracy: 0.8333 - val_loss: 1.5689 - val_accuracy: 0.5795 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.4254 - accuracy: 0.8414 - val_loss: 1.5371 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.4084 - accuracy: 0.8397 - val_loss: 1.6453 - val_accuracy: 0.5757 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3764 - accuracy: 0.8608 - val_loss: 1.7181 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.3888 - accuracy: 0.8576 - val_loss: 1.6924 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.3998 - accuracy: 0.8523 - val_loss: 1.6803 - val_accuracy: 0.5832 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3939 - accuracy: 0.8491 - val_loss: 1.7207 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3878 - accuracy: 0.8561 - val_loss: 1.7878 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.3394 - accuracy: 0.8714 - val_loss: 1.6926 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.3481 - accuracy: 0.8659 - val_loss: 1.7238 - val_accuracy: 0.5849 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.3406 - accuracy: 0.8723 - val_loss: 1.8921 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.3458 - accuracy: 0.8744 - val_loss: 1.9108 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3349 - accuracy: 0.8687 - val_loss: 1.8754 - val_accuracy: 0.5753 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.3135 - accuracy: 0.8792 - val_loss: 2.1649 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3478 - accuracy: 0.8724 - val_loss: 1.9098 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3036 - accuracy: 0.8902 - val_loss: 1.8727 - val_accuracy: 0.5707 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.3035 - accuracy: 0.8864 - val_loss: 1.9067 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.3175 - accuracy: 0.8813 - val_loss: 1.9904 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.3061 - accuracy: 0.8853 - val_loss: 2.0291 - val_accuracy: 0.5641 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.2719 - accuracy: 0.8954 - val_loss: 2.0810 - val_accuracy: 0.5711 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.2915 - accuracy: 0.8928 - val_loss: 2.0034 - val_accuracy: 0.5715 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.3079 - accuracy: 0.8871 - val_loss: 1.9079 - val_accuracy: 0.5790 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.2902 - accuracy: 0.8939 - val_loss: 1.9288 - val_accuracy: 0.5828 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.2595 - accuracy: 0.9064 - val_loss: 1.9758 - val_accuracy: 0.5832 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.2974 - accuracy: 0.8888 - val_loss: 1.8828 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.2512 - accuracy: 0.9121 - val_loss: 2.0712 - val_accuracy: 0.5815 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.2858 - accuracy: 0.9002 - val_loss: 2.1363 - val_accuracy: 0.5715 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.2465 - accuracy: 0.9110 - val_loss: 2.2739 - val_accuracy: 0.5695 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.2699 - accuracy: 0.9029 - val_loss: 2.0548 - val_accuracy: 0.5753 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.2611 - accuracy: 0.9053 - val_loss: 2.1055 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.2447 - accuracy: 0.9139 - val_loss: 1.9521 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.2337 - accuracy: 0.9137 - val_loss: 2.2569 - val_accuracy: 0.5869 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "226/226 [==============================] - 11s 49ms/step - loss: 0.2397 - accuracy: 0.9106 - val_loss: 2.3215 - val_accuracy: 0.5828 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.2560 - accuracy: 0.9071 - val_loss: 2.1769 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 10s 46ms/step - loss: 0.2082 - accuracy: 0.9275 - val_loss: 2.2625 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.3052 - accuracy: 0.8934 - val_loss: 2.3802 - val_accuracy: 0.5711 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.2476 - accuracy: 0.9065 - val_loss: 2.3369 - val_accuracy: 0.5799 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.2174 - accuracy: 0.9216 - val_loss: 2.3427 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.2133 - accuracy: 0.9203 - val_loss: 2.4125 - val_accuracy: 0.5761 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "226/226 [==============================] - 11s 48ms/step - loss: 0.2132 - accuracy: 0.9203 - val_loss: 2.2657 - val_accuracy: 0.5782 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.2416 - accuracy: 0.9140 - val_loss: 2.4078 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.1978 - accuracy: 0.9282 - val_loss: 2.5287 - val_accuracy: 0.5691 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "226/226 [==============================] - 10s 44ms/step - loss: 0.1947 - accuracy: 0.9283 - val_loss: 2.4880 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.2091 - accuracy: 0.9272 - val_loss: 2.4947 - val_accuracy: 0.5715 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "226/226 [==============================] - 10s 45ms/step - loss: 0.2331 - accuracy: 0.9219 - val_loss: 2.3476 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "226/226 [==============================] - 11s 47ms/step - loss: 0.2184 - accuracy: 0.9243 - val_loss: 2.4940 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "226/226 [==============================] - 10s 46ms/step - loss: 0.1993 - accuracy: 0.9294 - val_loss: 2.4539 - val_accuracy: 0.5695 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_all.h4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_all.h4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>Actual Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Labels Actual Labels\n",
       "0            angry          fear\n",
       "1              sad          fear\n",
       "2            happy         happy\n",
       "3              sad           sad\n",
       "4             fear           sad"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.1)\n",
    "history_1=model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp])\n",
    "model.save(\"cnn_all.h4\")\n",
    "pred_test_1 = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test_1)\n",
    "y_test_1 = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test_1.flatten()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7291fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.7577074e-07 2.3603586e-11 4.4294915e-01 5.5571675e-01 1.3335287e-03]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309f7483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>Actual Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fear</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fear</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Labels Actual Labels\n",
       "0            angry          fear\n",
       "1              sad          fear\n",
       "2            happy         happy\n",
       "3              sad           sad\n",
       "4             fear           sad\n",
       "5            happy         happy\n",
       "6            angry         angry\n",
       "7             fear         happy\n",
       "8             fear           sad\n",
       "9            angry         angry"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97443175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7211, 128) (7211, 5) (2404, 128) (2404, 5)\n",
      "(7211, 128) (7211, 5) (2404, 128) (2404, 5)\n",
      "(7211, 128, 1) (7211, 5) (2404, 128, 1) (2404, 5)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 128, 256)          1536      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 64, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 64, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 32, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 32, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 16, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 16, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 8, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 551,045\n",
      "Trainable params: 551,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 9s 66ms/step - loss: 1.5223 - accuracy: 0.3133 - val_loss: 1.4366 - val_accuracy: 0.3552 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.4228 - accuracy: 0.3689 - val_loss: 1.4112 - val_accuracy: 0.3744 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 1.3829 - accuracy: 0.3948 - val_loss: 1.3619 - val_accuracy: 0.4139 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 1.3594 - accuracy: 0.4146 - val_loss: 1.3260 - val_accuracy: 0.4314 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 1.3237 - accuracy: 0.4399 - val_loss: 1.2824 - val_accuracy: 0.4684 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 1.2849 - accuracy: 0.4607 - val_loss: 1.2723 - val_accuracy: 0.4659 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 1.2626 - accuracy: 0.4725 - val_loss: 1.2394 - val_accuracy: 0.4921 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.2391 - accuracy: 0.4856 - val_loss: 1.2118 - val_accuracy: 0.5087 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 1.2301 - accuracy: 0.4934 - val_loss: 1.2174 - val_accuracy: 0.5233 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 1.2027 - accuracy: 0.5107 - val_loss: 1.1996 - val_accuracy: 0.5025 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 1.1805 - accuracy: 0.5116 - val_loss: 1.1590 - val_accuracy: 0.5275 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 1.1736 - accuracy: 0.5162 - val_loss: 1.2027 - val_accuracy: 0.5324 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 1.1561 - accuracy: 0.5314 - val_loss: 1.1523 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 7s 66ms/step - loss: 1.1427 - accuracy: 0.5382 - val_loss: 1.1387 - val_accuracy: 0.5462 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 7s 66ms/step - loss: 1.1346 - accuracy: 0.5401 - val_loss: 1.1375 - val_accuracy: 0.5557 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 1.1250 - accuracy: 0.5449 - val_loss: 1.1252 - val_accuracy: 0.5645 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 1.1118 - accuracy: 0.5586 - val_loss: 1.1024 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 1.0898 - accuracy: 0.5504 - val_loss: 1.1179 - val_accuracy: 0.5607 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0802 - accuracy: 0.5677 - val_loss: 1.1429 - val_accuracy: 0.5449 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0853 - accuracy: 0.5612 - val_loss: 1.0944 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0622 - accuracy: 0.5691 - val_loss: 1.0953 - val_accuracy: 0.5728 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0531 - accuracy: 0.5725 - val_loss: 1.0903 - val_accuracy: 0.5678 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0498 - accuracy: 0.5748 - val_loss: 1.1207 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0392 - accuracy: 0.5847 - val_loss: 1.1094 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0328 - accuracy: 0.5840 - val_loss: 1.1097 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0140 - accuracy: 0.5876 - val_loss: 1.1208 - val_accuracy: 0.5545 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0121 - accuracy: 0.5876 - val_loss: 1.1230 - val_accuracy: 0.5649 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 1.0102 - accuracy: 0.5908 - val_loss: 1.1198 - val_accuracy: 0.5753 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.9884 - accuracy: 0.5949 - val_loss: 1.1058 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.9902 - accuracy: 0.5937 - val_loss: 1.1138 - val_accuracy: 0.5703 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.9805 - accuracy: 0.6006 - val_loss: 1.0921 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.9719 - accuracy: 0.6030 - val_loss: 1.1276 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.9666 - accuracy: 0.6057 - val_loss: 1.1342 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.9552 - accuracy: 0.6067 - val_loss: 1.0954 - val_accuracy: 0.5832 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.9430 - accuracy: 0.6121 - val_loss: 1.1094 - val_accuracy: 0.5749 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.9283 - accuracy: 0.6195 - val_loss: 1.1183 - val_accuracy: 0.5724 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.9349 - accuracy: 0.6181 - val_loss: 1.1199 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.9337 - accuracy: 0.6232 - val_loss: 1.1168 - val_accuracy: 0.5691 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.9083 - accuracy: 0.6236 - val_loss: 1.1590 - val_accuracy: 0.5707 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.9014 - accuracy: 0.6353 - val_loss: 1.1342 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.9181 - accuracy: 0.6271 - val_loss: 1.1508 - val_accuracy: 0.5553 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.9186 - accuracy: 0.6231 - val_loss: 1.1706 - val_accuracy: 0.5724 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8857 - accuracy: 0.6350 - val_loss: 1.1731 - val_accuracy: 0.5549 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8659 - accuracy: 0.6411 - val_loss: 1.1583 - val_accuracy: 0.5724 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8681 - accuracy: 0.6443 - val_loss: 1.1707 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8621 - accuracy: 0.6392 - val_loss: 1.1968 - val_accuracy: 0.5691 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8587 - accuracy: 0.6448 - val_loss: 1.1622 - val_accuracy: 0.5553 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8704 - accuracy: 0.6457 - val_loss: 1.2101 - val_accuracy: 0.5715 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8586 - accuracy: 0.6419 - val_loss: 1.3497 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.8536 - accuracy: 0.6475 - val_loss: 1.1881 - val_accuracy: 0.5786 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.8414 - accuracy: 0.6514 - val_loss: 1.2047 - val_accuracy: 0.5620 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.8282 - accuracy: 0.6608 - val_loss: 1.2577 - val_accuracy: 0.5562 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.8314 - accuracy: 0.6572 - val_loss: 1.1790 - val_accuracy: 0.5757 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 8s 67ms/step - loss: 0.8177 - accuracy: 0.6656 - val_loss: 1.2235 - val_accuracy: 0.5632 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 0.8273 - accuracy: 0.6641 - val_loss: 1.2040 - val_accuracy: 0.5753 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 7s 65ms/step - loss: 0.8119 - accuracy: 0.6623 - val_loss: 1.2293 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 7s 64ms/step - loss: 0.7871 - accuracy: 0.6704 - val_loss: 1.2748 - val_accuracy: 0.5736 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.8101 - accuracy: 0.6715 - val_loss: 1.2715 - val_accuracy: 0.5657 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7912 - accuracy: 0.6690 - val_loss: 1.2525 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7892 - accuracy: 0.6737 - val_loss: 1.2823 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7775 - accuracy: 0.6805 - val_loss: 1.2267 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7772 - accuracy: 0.6773 - val_loss: 1.3399 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7724 - accuracy: 0.6781 - val_loss: 1.3635 - val_accuracy: 0.5724 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.8075 - accuracy: 0.6666 - val_loss: 1.2294 - val_accuracy: 0.5661 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7675 - accuracy: 0.6824 - val_loss: 1.2391 - val_accuracy: 0.5691 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.7748 - accuracy: 0.6774 - val_loss: 1.2824 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7448 - accuracy: 0.6926 - val_loss: 1.3230 - val_accuracy: 0.5553 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7459 - accuracy: 0.6967 - val_loss: 1.3217 - val_accuracy: 0.5657 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7399 - accuracy: 0.6953 - val_loss: 1.5022 - val_accuracy: 0.5740 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7538 - accuracy: 0.6923 - val_loss: 1.3746 - val_accuracy: 0.5661 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.7559 - accuracy: 0.6930 - val_loss: 1.3070 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.7299 - accuracy: 0.7043 - val_loss: 1.3792 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7303 - accuracy: 0.6996 - val_loss: 1.4792 - val_accuracy: 0.5711 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7175 - accuracy: 0.7032 - val_loss: 1.5237 - val_accuracy: 0.5699 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7443 - accuracy: 0.6967 - val_loss: 1.5150 - val_accuracy: 0.5524 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7188 - accuracy: 0.6998 - val_loss: 1.4816 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7243 - accuracy: 0.7052 - val_loss: 1.4327 - val_accuracy: 0.5703 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 7s 61ms/step - loss: 0.7060 - accuracy: 0.7068 - val_loss: 1.4663 - val_accuracy: 0.5657 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.7182 - accuracy: 0.7048 - val_loss: 1.4017 - val_accuracy: 0.5715 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7031 - accuracy: 0.7114 - val_loss: 1.3677 - val_accuracy: 0.5715 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 7s 60ms/step - loss: 0.6941 - accuracy: 0.7167 - val_loss: 1.5433 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7320 - accuracy: 0.7071 - val_loss: 1.4967 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.7102 - accuracy: 0.7086 - val_loss: 1.4496 - val_accuracy: 0.5686 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.6842 - accuracy: 0.7149 - val_loss: 1.3994 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6887 - accuracy: 0.7206 - val_loss: 1.4636 - val_accuracy: 0.5603 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6721 - accuracy: 0.7222 - val_loss: 1.5439 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6617 - accuracy: 0.7292 - val_loss: 1.5496 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.6617 - accuracy: 0.7263 - val_loss: 1.5735 - val_accuracy: 0.5595 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6627 - accuracy: 0.7197 - val_loss: 1.6491 - val_accuracy: 0.5695 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6789 - accuracy: 0.7256 - val_loss: 1.5642 - val_accuracy: 0.5620 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6539 - accuracy: 0.7297 - val_loss: 1.6650 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6573 - accuracy: 0.7275 - val_loss: 1.6391 - val_accuracy: 0.5765 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6521 - accuracy: 0.7383 - val_loss: 1.6165 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6373 - accuracy: 0.7373 - val_loss: 1.6337 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6407 - accuracy: 0.7382 - val_loss: 1.7245 - val_accuracy: 0.5678 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6499 - accuracy: 0.7290 - val_loss: 1.6513 - val_accuracy: 0.5616 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6651 - accuracy: 0.7276 - val_loss: 1.6116 - val_accuracy: 0.5599 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.6494 - accuracy: 0.7314 - val_loss: 1.6060 - val_accuracy: 0.5728 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 7s 62ms/step - loss: 0.6468 - accuracy: 0.7358 - val_loss: 1.6327 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 7s 63ms/step - loss: 0.6285 - accuracy: 0.7440 - val_loss: 1.6692 - val_accuracy: 0.5645 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_mel.h4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_mel.h4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>Actual Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Labels Actual Labels\n",
       "0              sad          fear\n",
       "1              sad          fear\n",
       "2            angry         happy\n",
       "3              sad           sad\n",
       "4              sad           sad\n",
       "5            happy         happy\n",
       "6            angry         angry\n",
       "7            happy         happy\n",
       "8              sad           sad\n",
       "9            angry         angry"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\"\"d=pd.read_csv(r\"C:\\Users\\dhanu\\Desktop\\Mini Project\\code_new\\mel.csv\")\n",
    "\n",
    "X = d.iloc[: ,:-1].values\n",
    "Y = d['label'].values\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\"\"\"\n",
    "print(x_train_mel.shape, y_train.shape, x_test_mel.shape, y_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train_mel)\n",
    "x_test = scaler.transform(x_test_mel)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.1)\n",
    "history_2=model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp])\n",
    "model.save(\"cnn_mel.h4\")\n",
    "pred_test_2 = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test_2)\n",
    "y_test_2 = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test_2.flatten()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef8e5682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 21, 256)           1536      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 11, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 11, 256)           327936    \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 6, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 6, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 3, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 3, 128)            0         \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 3, 64)             41024     \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 2, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 538,757\n",
      "Trainable params: 538,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 4s 21ms/step - loss: 1.4954 - accuracy: 0.3201 - val_loss: 1.3369 - val_accuracy: 0.4185 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 1.3354 - accuracy: 0.4237 - val_loss: 1.2483 - val_accuracy: 0.4667 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 1.2628 - accuracy: 0.4604 - val_loss: 1.1591 - val_accuracy: 0.5141 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 1.2081 - accuracy: 0.4991 - val_loss: 1.1089 - val_accuracy: 0.5395 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 1.1466 - accuracy: 0.5181 - val_loss: 1.0885 - val_accuracy: 0.5453 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 1.1117 - accuracy: 0.5364 - val_loss: 1.0575 - val_accuracy: 0.5557 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 1.0796 - accuracy: 0.5458 - val_loss: 1.0610 - val_accuracy: 0.5599 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 1.0434 - accuracy: 0.5608 - val_loss: 1.0660 - val_accuracy: 0.5403 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 1.0273 - accuracy: 0.5719 - val_loss: 1.0392 - val_accuracy: 0.5724 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 1.0156 - accuracy: 0.5858 - val_loss: 1.0315 - val_accuracy: 0.5832 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.9998 - accuracy: 0.5872 - val_loss: 1.0218 - val_accuracy: 0.5765 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.9662 - accuracy: 0.6002 - val_loss: 1.0343 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.9400 - accuracy: 0.6150 - val_loss: 1.0871 - val_accuracy: 0.5645 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.9407 - accuracy: 0.6131 - val_loss: 0.9842 - val_accuracy: 0.5857 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.9135 - accuracy: 0.6275 - val_loss: 1.0144 - val_accuracy: 0.5836 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.8954 - accuracy: 0.6354 - val_loss: 1.0188 - val_accuracy: 0.5790 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.8668 - accuracy: 0.6537 - val_loss: 1.0352 - val_accuracy: 0.5745 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.8534 - accuracy: 0.6573 - val_loss: 1.0156 - val_accuracy: 0.5928 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.8323 - accuracy: 0.6708 - val_loss: 1.0193 - val_accuracy: 0.5832 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.8166 - accuracy: 0.6772 - val_loss: 1.0348 - val_accuracy: 0.5874 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.7954 - accuracy: 0.6870 - val_loss: 1.0446 - val_accuracy: 0.5849 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.7596 - accuracy: 0.7064 - val_loss: 1.0615 - val_accuracy: 0.5874 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.7440 - accuracy: 0.7092 - val_loss: 1.1212 - val_accuracy: 0.5753 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.7139 - accuracy: 0.7250 - val_loss: 1.0817 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.7067 - accuracy: 0.7229 - val_loss: 1.1373 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.6700 - accuracy: 0.7401 - val_loss: 1.1433 - val_accuracy: 0.5695 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.6354 - accuracy: 0.7552 - val_loss: 1.1686 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.6124 - accuracy: 0.7651 - val_loss: 1.1763 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.6091 - accuracy: 0.7624 - val_loss: 1.1772 - val_accuracy: 0.5824 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.5561 - accuracy: 0.7844 - val_loss: 1.3396 - val_accuracy: 0.5678 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.5572 - accuracy: 0.7866 - val_loss: 1.3236 - val_accuracy: 0.5869 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.5161 - accuracy: 0.8064 - val_loss: 1.3245 - val_accuracy: 0.5778 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.5201 - accuracy: 0.8040 - val_loss: 1.2883 - val_accuracy: 0.5728 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.4942 - accuracy: 0.8132 - val_loss: 1.3575 - val_accuracy: 0.5728 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.4561 - accuracy: 0.8251 - val_loss: 1.3805 - val_accuracy: 0.5711 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.4395 - accuracy: 0.8330 - val_loss: 1.4931 - val_accuracy: 0.5803 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.4187 - accuracy: 0.8447 - val_loss: 1.4805 - val_accuracy: 0.5661 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.4201 - accuracy: 0.8480 - val_loss: 1.5569 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.3843 - accuracy: 0.8574 - val_loss: 1.6490 - val_accuracy: 0.5778 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.3677 - accuracy: 0.8631 - val_loss: 1.7291 - val_accuracy: 0.5828 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.3462 - accuracy: 0.8771 - val_loss: 1.6384 - val_accuracy: 0.5749 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.3375 - accuracy: 0.8792 - val_loss: 1.7328 - val_accuracy: 0.5641 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.3292 - accuracy: 0.8816 - val_loss: 1.8291 - val_accuracy: 0.5649 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.3194 - accuracy: 0.8831 - val_loss: 1.8096 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2755 - accuracy: 0.9013 - val_loss: 1.8865 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2920 - accuracy: 0.8911 - val_loss: 1.9674 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2867 - accuracy: 0.8975 - val_loss: 1.9911 - val_accuracy: 0.5607 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.2526 - accuracy: 0.9079 - val_loss: 2.2366 - val_accuracy: 0.5624 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2741 - accuracy: 0.9036 - val_loss: 2.0525 - val_accuracy: 0.5620 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2313 - accuracy: 0.9161 - val_loss: 2.1910 - val_accuracy: 0.5628 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2427 - accuracy: 0.9150 - val_loss: 2.2100 - val_accuracy: 0.5491 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2422 - accuracy: 0.9150 - val_loss: 2.2891 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2212 - accuracy: 0.9236 - val_loss: 2.1274 - val_accuracy: 0.5691 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2370 - accuracy: 0.9115 - val_loss: 2.1747 - val_accuracy: 0.5611 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2201 - accuracy: 0.9246 - val_loss: 2.3239 - val_accuracy: 0.5649 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1885 - accuracy: 0.9312 - val_loss: 2.5259 - val_accuracy: 0.5570 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.2013 - accuracy: 0.9323 - val_loss: 2.4796 - val_accuracy: 0.5620 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1702 - accuracy: 0.9413 - val_loss: 2.5022 - val_accuracy: 0.5628 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1865 - accuracy: 0.9330 - val_loss: 2.5796 - val_accuracy: 0.5587 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1791 - accuracy: 0.9383 - val_loss: 2.5604 - val_accuracy: 0.5686 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1970 - accuracy: 0.9312 - val_loss: 2.6453 - val_accuracy: 0.5649 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1833 - accuracy: 0.9363 - val_loss: 2.6103 - val_accuracy: 0.5624 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1725 - accuracy: 0.9409 - val_loss: 2.5201 - val_accuracy: 0.5591 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1586 - accuracy: 0.9443 - val_loss: 2.5449 - val_accuracy: 0.5699 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1368 - accuracy: 0.9531 - val_loss: 2.8598 - val_accuracy: 0.5657 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1564 - accuracy: 0.9473 - val_loss: 2.7864 - val_accuracy: 0.5632 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1784 - accuracy: 0.9383 - val_loss: 2.3740 - val_accuracy: 0.5507 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1279 - accuracy: 0.9588 - val_loss: 2.7455 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1483 - accuracy: 0.9515 - val_loss: 2.7944 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1288 - accuracy: 0.9563 - val_loss: 2.8038 - val_accuracy: 0.5512 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1382 - accuracy: 0.9516 - val_loss: 3.0127 - val_accuracy: 0.5674 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1215 - accuracy: 0.9592 - val_loss: 3.0432 - val_accuracy: 0.5458 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.1408 - accuracy: 0.9533 - val_loss: 2.9269 - val_accuracy: 0.5611 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1276 - accuracy: 0.9585 - val_loss: 2.7580 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1444 - accuracy: 0.9540 - val_loss: 2.7163 - val_accuracy: 0.5399 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1227 - accuracy: 0.9563 - val_loss: 2.9211 - val_accuracy: 0.5682 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.0998 - accuracy: 0.9649 - val_loss: 3.1979 - val_accuracy: 0.5641 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1312 - accuracy: 0.9578 - val_loss: 2.9418 - val_accuracy: 0.5591 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1035 - accuracy: 0.9646 - val_loss: 3.0914 - val_accuracy: 0.5611 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1216 - accuracy: 0.9601 - val_loss: 2.9713 - val_accuracy: 0.5507 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1119 - accuracy: 0.9614 - val_loss: 3.1178 - val_accuracy: 0.5528 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1210 - accuracy: 0.9576 - val_loss: 2.9005 - val_accuracy: 0.5686 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1309 - accuracy: 0.9585 - val_loss: 2.9474 - val_accuracy: 0.5657 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1038 - accuracy: 0.9653 - val_loss: 3.2422 - val_accuracy: 0.5645 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.0901 - accuracy: 0.9703 - val_loss: 3.3522 - val_accuracy: 0.5541 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1424 - accuracy: 0.9555 - val_loss: 2.7272 - val_accuracy: 0.5603 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1361 - accuracy: 0.9560 - val_loss: 2.9515 - val_accuracy: 0.5545 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.0722 - accuracy: 0.9773 - val_loss: 3.1532 - val_accuracy: 0.5661 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1543 - accuracy: 0.9515 - val_loss: 2.6397 - val_accuracy: 0.5591 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.0884 - accuracy: 0.9705 - val_loss: 3.2208 - val_accuracy: 0.5645 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 2s 21ms/step - loss: 0.1087 - accuracy: 0.9674 - val_loss: 2.9838 - val_accuracy: 0.5566 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 2s 22ms/step - loss: 0.0914 - accuracy: 0.9716 - val_loss: 3.3802 - val_accuracy: 0.5641 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1108 - accuracy: 0.9649 - val_loss: 2.9520 - val_accuracy: 0.5512 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 3.2992 - val_accuracy: 0.5512 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.1137 - accuracy: 0.9648 - val_loss: 3.1215 - val_accuracy: 0.5549 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.0797 - accuracy: 0.9742 - val_loss: 3.4764 - val_accuracy: 0.5620 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1191 - accuracy: 0.9653 - val_loss: 3.2989 - val_accuracy: 0.5478 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 2s 20ms/step - loss: 0.0964 - accuracy: 0.9692 - val_loss: 3.4423 - val_accuracy: 0.5599 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 2s 19ms/step - loss: 0.1236 - accuracy: 0.9633 - val_loss: 2.9126 - val_accuracy: 0.5524 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 2s 18ms/step - loss: 0.0724 - accuracy: 0.9752 - val_loss: 3.3352 - val_accuracy: 0.5620 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_mfcc.h4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_mfcc.h4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>Actual Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Labels Actual Labels\n",
       "0            angry          fear\n",
       "1              sad          fear\n",
       "2            happy         happy\n",
       "3              sad           sad\n",
       "4              sad           sad\n",
       "5          disgust         happy\n",
       "6            angry         angry\n",
       "7          disgust         happy\n",
       "8              sad           sad\n",
       "9            angry         angry"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\"\"d=pd.read_csv(r\"C:\\Users\\dhanu\\Desktop\\Mini Project\\code_new\\mfcc.csv\")\n",
    "\n",
    "X = d.iloc[: ,:-1].values\n",
    "Y = d['label'].values\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\"\"\"\n",
    "x_train_mfcc.shape, y_train.shape, x_test_mfcc.shape, y_test.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train_mfcc)\n",
    "x_test = scaler.transform(x_test_mfcc)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.1)\n",
    "history_3=model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp])\n",
    "model.save(\"cnn_mfcc.h4\")\n",
    "pred_test_3 = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test_3)\n",
    "y_test_3 = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test_3.flatten()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa221c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 1, 256)            1536      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 1, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 1, 256)            327936    \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 1, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 1, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 1, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 128)            0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 1, 64)             41024     \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 536,709\n",
      "Trainable params: 536,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 1.4973 - accuracy: 0.3309 - val_loss: 1.4338 - val_accuracy: 0.3802 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4512 - accuracy: 0.3680 - val_loss: 1.4255 - val_accuracy: 0.3852 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4463 - accuracy: 0.3782 - val_loss: 1.4141 - val_accuracy: 0.3943 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4420 - accuracy: 0.3761 - val_loss: 1.4118 - val_accuracy: 0.3852 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4417 - accuracy: 0.3757 - val_loss: 1.4157 - val_accuracy: 0.3877 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4428 - accuracy: 0.3755 - val_loss: 1.4104 - val_accuracy: 0.3856 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4431 - accuracy: 0.3758 - val_loss: 1.4095 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4359 - accuracy: 0.3872 - val_loss: 1.4129 - val_accuracy: 0.3869 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4370 - accuracy: 0.3784 - val_loss: 1.4220 - val_accuracy: 0.3814 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4336 - accuracy: 0.3833 - val_loss: 1.4080 - val_accuracy: 0.3918 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4383 - accuracy: 0.3821 - val_loss: 1.4094 - val_accuracy: 0.3856 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.4327 - accuracy: 0.3827 - val_loss: 1.4177 - val_accuracy: 0.3869 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.4326 - accuracy: 0.3830 - val_loss: 1.4114 - val_accuracy: 0.3914 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4364 - accuracy: 0.3821 - val_loss: 1.4097 - val_accuracy: 0.3839 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4350 - accuracy: 0.3826 - val_loss: 1.4480 - val_accuracy: 0.3557 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4334 - accuracy: 0.3815 - val_loss: 1.4096 - val_accuracy: 0.3906 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4317 - accuracy: 0.3805 - val_loss: 1.4127 - val_accuracy: 0.3935 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4359 - accuracy: 0.3811 - val_loss: 1.4098 - val_accuracy: 0.3839 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.4332 - accuracy: 0.3848 - val_loss: 1.4157 - val_accuracy: 0.3943 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4338 - accuracy: 0.3819 - val_loss: 1.4066 - val_accuracy: 0.3914 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4293 - accuracy: 0.3844 - val_loss: 1.4106 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4344 - accuracy: 0.3826 - val_loss: 1.4082 - val_accuracy: 0.3831 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4324 - accuracy: 0.3822 - val_loss: 1.4111 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4326 - accuracy: 0.3821 - val_loss: 1.4154 - val_accuracy: 0.3835 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4304 - accuracy: 0.3857 - val_loss: 1.4080 - val_accuracy: 0.3885 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4299 - accuracy: 0.3793 - val_loss: 1.4067 - val_accuracy: 0.3877 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4283 - accuracy: 0.3775 - val_loss: 1.4070 - val_accuracy: 0.3931 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4269 - accuracy: 0.3843 - val_loss: 1.4107 - val_accuracy: 0.3894 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4308 - accuracy: 0.3807 - val_loss: 1.4077 - val_accuracy: 0.3877 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4347 - accuracy: 0.3787 - val_loss: 1.4061 - val_accuracy: 0.3856 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4324 - accuracy: 0.3840 - val_loss: 1.4053 - val_accuracy: 0.3860 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4311 - accuracy: 0.3819 - val_loss: 1.4123 - val_accuracy: 0.3906 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4280 - accuracy: 0.3841 - val_loss: 1.4061 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4268 - accuracy: 0.3829 - val_loss: 1.4064 - val_accuracy: 0.3906 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4289 - accuracy: 0.3854 - val_loss: 1.4156 - val_accuracy: 0.3898 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4289 - accuracy: 0.3783 - val_loss: 1.4086 - val_accuracy: 0.3885 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4324 - accuracy: 0.3834 - val_loss: 1.4075 - val_accuracy: 0.3844 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4329 - accuracy: 0.3836 - val_loss: 1.4052 - val_accuracy: 0.3894 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4307 - accuracy: 0.3823 - val_loss: 1.4073 - val_accuracy: 0.3894 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4262 - accuracy: 0.3840 - val_loss: 1.4063 - val_accuracy: 0.3931 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4315 - accuracy: 0.3823 - val_loss: 1.4106 - val_accuracy: 0.3860 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.4272 - accuracy: 0.3862 - val_loss: 1.4092 - val_accuracy: 0.3902 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4279 - accuracy: 0.3823 - val_loss: 1.4078 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.4279 - accuracy: 0.3787 - val_loss: 1.4085 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4302 - accuracy: 0.3837 - val_loss: 1.4077 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4265 - accuracy: 0.3846 - val_loss: 1.4050 - val_accuracy: 0.3914 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.4277 - accuracy: 0.3859 - val_loss: 1.4119 - val_accuracy: 0.3873 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4274 - accuracy: 0.3830 - val_loss: 1.4104 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4253 - accuracy: 0.3851 - val_loss: 1.4057 - val_accuracy: 0.3964 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4245 - accuracy: 0.3834 - val_loss: 1.4056 - val_accuracy: 0.3918 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4282 - accuracy: 0.3805 - val_loss: 1.4071 - val_accuracy: 0.3898 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4282 - accuracy: 0.3847 - val_loss: 1.4062 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4283 - accuracy: 0.3843 - val_loss: 1.4146 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4269 - accuracy: 0.3836 - val_loss: 1.4054 - val_accuracy: 0.3885 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4249 - accuracy: 0.3821 - val_loss: 1.4073 - val_accuracy: 0.3910 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4253 - accuracy: 0.3826 - val_loss: 1.4072 - val_accuracy: 0.3898 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4274 - accuracy: 0.3866 - val_loss: 1.4168 - val_accuracy: 0.3885 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4252 - accuracy: 0.3826 - val_loss: 1.4036 - val_accuracy: 0.3931 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4229 - accuracy: 0.3834 - val_loss: 1.4056 - val_accuracy: 0.3943 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4254 - accuracy: 0.3839 - val_loss: 1.4082 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4254 - accuracy: 0.3839 - val_loss: 1.4073 - val_accuracy: 0.3864 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4218 - accuracy: 0.3848 - val_loss: 1.4071 - val_accuracy: 0.3956 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4302 - accuracy: 0.3812 - val_loss: 1.4059 - val_accuracy: 0.3873 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4273 - accuracy: 0.3801 - val_loss: 1.4072 - val_accuracy: 0.3943 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4249 - accuracy: 0.3843 - val_loss: 1.4120 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4248 - accuracy: 0.3827 - val_loss: 1.4138 - val_accuracy: 0.3823 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4229 - accuracy: 0.3782 - val_loss: 1.4084 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4240 - accuracy: 0.3850 - val_loss: 1.4052 - val_accuracy: 0.3889 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4223 - accuracy: 0.3815 - val_loss: 1.4080 - val_accuracy: 0.3914 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4265 - accuracy: 0.3862 - val_loss: 1.4068 - val_accuracy: 0.3898 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4248 - accuracy: 0.3830 - val_loss: 1.4204 - val_accuracy: 0.3844 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4263 - accuracy: 0.3805 - val_loss: 1.4069 - val_accuracy: 0.3898 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4261 - accuracy: 0.3790 - val_loss: 1.4153 - val_accuracy: 0.3781 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4258 - accuracy: 0.3843 - val_loss: 1.4069 - val_accuracy: 0.3923 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4254 - accuracy: 0.3815 - val_loss: 1.4146 - val_accuracy: 0.3864 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4253 - accuracy: 0.3839 - val_loss: 1.4069 - val_accuracy: 0.3910 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4247 - accuracy: 0.3809 - val_loss: 1.4069 - val_accuracy: 0.3844 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4248 - accuracy: 0.3837 - val_loss: 1.4070 - val_accuracy: 0.3902 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4254 - accuracy: 0.3857 - val_loss: 1.4071 - val_accuracy: 0.3906 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4264 - accuracy: 0.3815 - val_loss: 1.4096 - val_accuracy: 0.3956 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4221 - accuracy: 0.3859 - val_loss: 1.4058 - val_accuracy: 0.3927 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4214 - accuracy: 0.3818 - val_loss: 1.4114 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4287 - accuracy: 0.3832 - val_loss: 1.4047 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4270 - accuracy: 0.3808 - val_loss: 1.4074 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4234 - accuracy: 0.3858 - val_loss: 1.4067 - val_accuracy: 0.3869 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4263 - accuracy: 0.3829 - val_loss: 1.4082 - val_accuracy: 0.3939 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4243 - accuracy: 0.3823 - val_loss: 1.4108 - val_accuracy: 0.3873 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4252 - accuracy: 0.3823 - val_loss: 1.4054 - val_accuracy: 0.3885 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4215 - accuracy: 0.3876 - val_loss: 1.4077 - val_accuracy: 0.3914 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4242 - accuracy: 0.3826 - val_loss: 1.4051 - val_accuracy: 0.3906 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4227 - accuracy: 0.3893 - val_loss: 1.4102 - val_accuracy: 0.3856 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4252 - accuracy: 0.3793 - val_loss: 1.4091 - val_accuracy: 0.3935 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4229 - accuracy: 0.3812 - val_loss: 1.4045 - val_accuracy: 0.3931 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4255 - accuracy: 0.3837 - val_loss: 1.4054 - val_accuracy: 0.3910 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4244 - accuracy: 0.3841 - val_loss: 1.4056 - val_accuracy: 0.3906 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4208 - accuracy: 0.3819 - val_loss: 1.4093 - val_accuracy: 0.3898 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4238 - accuracy: 0.3848 - val_loss: 1.4178 - val_accuracy: 0.3748 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4232 - accuracy: 0.3850 - val_loss: 1.4066 - val_accuracy: 0.3914 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4243 - accuracy: 0.3850 - val_loss: 1.4037 - val_accuracy: 0.3902 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 1.4229 - accuracy: 0.3827 - val_loss: 1.4070 - val_accuracy: 0.3956 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_rms.h4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_rms.h4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>Actual Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Labels Actual Labels\n",
       "0            angry          fear\n",
       "1              sad          fear\n",
       "2            angry         happy\n",
       "3              sad           sad\n",
       "4              sad           sad\n",
       "5            angry         happy\n",
       "6            angry         angry\n",
       "7          disgust         happy\n",
       "8              sad           sad\n",
       "9            angry         angry"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\"\"d=pd.read_csv(r\"C:\\Users\\dhanu\\Desktop\\Mini Project\\code_new\\rms.csv\")\n",
    "\n",
    "X = d.iloc[: ,:-1].values\n",
    "Y = d['label'].values\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\"\"\"\n",
    "x_train_rms.shape, y_train.shape, x_test_rms.shape, y_test.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train_rms)\n",
    "x_test = scaler.transform(x_test_rms)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.1)\n",
    "history_4=model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp])\n",
    "model.save(\"cnn_rms.h4\")\n",
    "pred_test_4 = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test_4)\n",
    "y_test_4 = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test_4.flatten()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4000ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7211, 11) (7211, 5) (2404, 11) (2404, 5)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_16 (Conv1D)          (None, 11, 256)           1536      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 6, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 6, 256)            327936    \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 3, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 3, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 2, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2, 128)            0         \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 2, 64)             41024     \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 536,709\n",
      "Trainable params: 536,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 3s 15ms/step - loss: 1.5716 - accuracy: 0.2468 - val_loss: 1.5004 - val_accuracy: 0.3236 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 1.5003 - accuracy: 0.3018 - val_loss: 1.4857 - val_accuracy: 0.3290 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.4621 - accuracy: 0.3301 - val_loss: 1.4364 - val_accuracy: 0.3361 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.4381 - accuracy: 0.3472 - val_loss: 1.4373 - val_accuracy: 0.3511 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.4346 - accuracy: 0.3556 - val_loss: 1.4240 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.4099 - accuracy: 0.3726 - val_loss: 1.4170 - val_accuracy: 0.3665 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3973 - accuracy: 0.3819 - val_loss: 1.4130 - val_accuracy: 0.3665 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3837 - accuracy: 0.3884 - val_loss: 1.4000 - val_accuracy: 0.3727 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3716 - accuracy: 0.4005 - val_loss: 1.4177 - val_accuracy: 0.3590 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3727 - accuracy: 0.3959 - val_loss: 1.4087 - val_accuracy: 0.3694 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3571 - accuracy: 0.4044 - val_loss: 1.4072 - val_accuracy: 0.3814 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3448 - accuracy: 0.4163 - val_loss: 1.4033 - val_accuracy: 0.3777 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3358 - accuracy: 0.4202 - val_loss: 1.4019 - val_accuracy: 0.3839 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3261 - accuracy: 0.4257 - val_loss: 1.4107 - val_accuracy: 0.3777 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3096 - accuracy: 0.4334 - val_loss: 1.4253 - val_accuracy: 0.3810 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.3094 - accuracy: 0.4332 - val_loss: 1.4149 - val_accuracy: 0.3727 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2936 - accuracy: 0.4392 - val_loss: 1.4165 - val_accuracy: 0.3802 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2875 - accuracy: 0.4496 - val_loss: 1.4208 - val_accuracy: 0.3819 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2619 - accuracy: 0.4632 - val_loss: 1.4608 - val_accuracy: 0.3706 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2495 - accuracy: 0.4705 - val_loss: 1.4336 - val_accuracy: 0.3819 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2364 - accuracy: 0.4797 - val_loss: 1.4272 - val_accuracy: 0.3819 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2235 - accuracy: 0.4818 - val_loss: 1.4471 - val_accuracy: 0.3686 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2075 - accuracy: 0.4915 - val_loss: 1.4614 - val_accuracy: 0.3806 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1946 - accuracy: 0.4947 - val_loss: 1.4710 - val_accuracy: 0.3735 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1668 - accuracy: 0.5094 - val_loss: 1.5180 - val_accuracy: 0.3577 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1627 - accuracy: 0.5128 - val_loss: 1.5745 - val_accuracy: 0.3727 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1334 - accuracy: 0.5292 - val_loss: 1.5745 - val_accuracy: 0.3573 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1291 - accuracy: 0.5277 - val_loss: 1.6037 - val_accuracy: 0.3710 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.1034 - accuracy: 0.5460 - val_loss: 1.5996 - val_accuracy: 0.3557 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.0758 - accuracy: 0.5564 - val_loss: 1.6164 - val_accuracy: 0.3502 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.0475 - accuracy: 0.5725 - val_loss: 1.6589 - val_accuracy: 0.3515 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.0257 - accuracy: 0.5819 - val_loss: 1.7142 - val_accuracy: 0.3473 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.0130 - accuracy: 0.5860 - val_loss: 1.6979 - val_accuracy: 0.3544 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.9611 - accuracy: 0.6091 - val_loss: 1.7279 - val_accuracy: 0.3507 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.9414 - accuracy: 0.6225 - val_loss: 1.8470 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.9338 - accuracy: 0.6217 - val_loss: 1.8869 - val_accuracy: 0.3519 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.8949 - accuracy: 0.6375 - val_loss: 1.9394 - val_accuracy: 0.3661 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.8783 - accuracy: 0.6475 - val_loss: 1.8798 - val_accuracy: 0.3340 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.8510 - accuracy: 0.6568 - val_loss: 2.0270 - val_accuracy: 0.3448 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.8152 - accuracy: 0.6722 - val_loss: 2.0770 - val_accuracy: 0.3390 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.8031 - accuracy: 0.6827 - val_loss: 2.1946 - val_accuracy: 0.3498 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.7584 - accuracy: 0.7006 - val_loss: 2.2657 - val_accuracy: 0.3461 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.7464 - accuracy: 0.7071 - val_loss: 2.1815 - val_accuracy: 0.3515 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.7622 - accuracy: 0.7006 - val_loss: 2.3669 - val_accuracy: 0.3469 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.7106 - accuracy: 0.7186 - val_loss: 2.3177 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.7079 - accuracy: 0.7236 - val_loss: 2.4352 - val_accuracy: 0.3290 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6634 - accuracy: 0.7337 - val_loss: 2.5122 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6375 - accuracy: 0.7548 - val_loss: 2.6650 - val_accuracy: 0.3382 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6336 - accuracy: 0.7526 - val_loss: 2.6023 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6058 - accuracy: 0.7629 - val_loss: 2.6183 - val_accuracy: 0.3390 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6107 - accuracy: 0.7656 - val_loss: 2.7463 - val_accuracy: 0.3340 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6050 - accuracy: 0.7677 - val_loss: 2.6417 - val_accuracy: 0.3415 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5940 - accuracy: 0.7702 - val_loss: 2.7988 - val_accuracy: 0.3270 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5443 - accuracy: 0.7869 - val_loss: 3.0358 - val_accuracy: 0.3374 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.5085 - accuracy: 0.8071 - val_loss: 3.0211 - val_accuracy: 0.3390 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4939 - accuracy: 0.8128 - val_loss: 3.0275 - val_accuracy: 0.3403 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4880 - accuracy: 0.8095 - val_loss: 3.2190 - val_accuracy: 0.3469 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4764 - accuracy: 0.8150 - val_loss: 3.2931 - val_accuracy: 0.3432 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4533 - accuracy: 0.8271 - val_loss: 3.3124 - val_accuracy: 0.3453 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4719 - accuracy: 0.8226 - val_loss: 3.2622 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4740 - accuracy: 0.8154 - val_loss: 3.1075 - val_accuracy: 0.3328 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4460 - accuracy: 0.8275 - val_loss: 3.5095 - val_accuracy: 0.3328 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4127 - accuracy: 0.8394 - val_loss: 3.4976 - val_accuracy: 0.3365 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4134 - accuracy: 0.8414 - val_loss: 3.6393 - val_accuracy: 0.3448 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4272 - accuracy: 0.8382 - val_loss: 3.4652 - val_accuracy: 0.3361 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4904 - accuracy: 0.8264 - val_loss: 3.2325 - val_accuracy: 0.3340 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4041 - accuracy: 0.8490 - val_loss: 3.5535 - val_accuracy: 0.3419 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3727 - accuracy: 0.8588 - val_loss: 3.7778 - val_accuracy: 0.3357 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3783 - accuracy: 0.8574 - val_loss: 3.7045 - val_accuracy: 0.3415 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3960 - accuracy: 0.8479 - val_loss: 3.5730 - val_accuracy: 0.3315 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3756 - accuracy: 0.8645 - val_loss: 3.7461 - val_accuracy: 0.3469 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3530 - accuracy: 0.8698 - val_loss: 3.8524 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3410 - accuracy: 0.8714 - val_loss: 4.0720 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3472 - accuracy: 0.8717 - val_loss: 3.8427 - val_accuracy: 0.3386 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3606 - accuracy: 0.8690 - val_loss: 3.7242 - val_accuracy: 0.3478 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3315 - accuracy: 0.8748 - val_loss: 4.0084 - val_accuracy: 0.3357 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2863 - accuracy: 0.8903 - val_loss: 4.2497 - val_accuracy: 0.3386 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3533 - accuracy: 0.8737 - val_loss: 3.7986 - val_accuracy: 0.3220 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3206 - accuracy: 0.8788 - val_loss: 4.1419 - val_accuracy: 0.3299 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3005 - accuracy: 0.8860 - val_loss: 4.2307 - val_accuracy: 0.3394 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3152 - accuracy: 0.8803 - val_loss: 4.1681 - val_accuracy: 0.3332 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2825 - accuracy: 0.8983 - val_loss: 4.2197 - val_accuracy: 0.3332 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2767 - accuracy: 0.8971 - val_loss: 4.4333 - val_accuracy: 0.3378 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3266 - accuracy: 0.8778 - val_loss: 4.2071 - val_accuracy: 0.3324 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.3171 - accuracy: 0.8882 - val_loss: 4.1908 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2983 - accuracy: 0.8896 - val_loss: 4.2411 - val_accuracy: 0.3245 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2796 - accuracy: 0.8946 - val_loss: 4.2423 - val_accuracy: 0.3353 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2869 - accuracy: 0.8932 - val_loss: 4.2415 - val_accuracy: 0.3432 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2567 - accuracy: 0.9071 - val_loss: 4.3280 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2763 - accuracy: 0.8978 - val_loss: 4.3612 - val_accuracy: 0.3457 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2443 - accuracy: 0.9119 - val_loss: 4.3542 - val_accuracy: 0.3423 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2427 - accuracy: 0.9135 - val_loss: 4.5649 - val_accuracy: 0.3386 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2553 - accuracy: 0.9045 - val_loss: 4.5487 - val_accuracy: 0.3319 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2409 - accuracy: 0.9140 - val_loss: 4.6057 - val_accuracy: 0.3261 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2678 - accuracy: 0.9040 - val_loss: 4.2954 - val_accuracy: 0.3394 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2405 - accuracy: 0.9149 - val_loss: 4.6473 - val_accuracy: 0.3340 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2437 - accuracy: 0.9096 - val_loss: 4.9023 - val_accuracy: 0.3357 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2339 - accuracy: 0.9147 - val_loss: 4.7258 - val_accuracy: 0.3315 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2319 - accuracy: 0.9155 - val_loss: 4.6974 - val_accuracy: 0.3399 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.2321 - accuracy: 0.9171 - val_loss: 4.8586 - val_accuracy: 0.3336 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_chroma.h4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_chroma.h4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>Actual Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sad</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>disgust</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>disgust</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fear</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Labels Actual Labels\n",
       "0            angry          fear\n",
       "1             fear          fear\n",
       "2              sad         happy\n",
       "3            angry           sad\n",
       "4            angry           sad\n",
       "5          disgust         happy\n",
       "6              sad         angry\n",
       "7          disgust         happy\n",
       "8          disgust           sad\n",
       "9             fear         angry"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\"\"d=pd.read_csv(r\"C:\\Users\\dhanu\\Desktop\\Mini Project\\code_new\\chroma_stft.csv\")\n",
    "X = d.iloc[: ,:-1].values\n",
    "Y = d['label'].values\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\"\"\"\n",
    "print(x_train_chroma_stft.shape, y_train.shape, x_test_chroma_stft.shape, y_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train_chroma_stft)\n",
    "x_test = scaler.transform(x_test_chroma_stft)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.1)\n",
    "history_5=model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp])\n",
    "model.save(\"cnn_chroma.h4\")\n",
    "pred_test_5 = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test_5)\n",
    "y_test_5 = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test_5.flatten()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "025c61ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7211, 1) (7211, 5) (2404, 1) (2404, 5)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_20 (Conv1D)          (None, 1, 256)            1536      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 1, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 1, 256)            327936    \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 1, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_22 (Conv1D)          (None, 1, 128)            163968    \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 1, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1, 128)            0         \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 1, 64)             41024     \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 1, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 536,709\n",
      "Trainable params: 536,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 1.5743 - accuracy: 0.2790 - val_loss: 1.5528 - val_accuracy: 0.2962 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5551 - accuracy: 0.2940 - val_loss: 1.5417 - val_accuracy: 0.3062 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5524 - accuracy: 0.2925 - val_loss: 1.5389 - val_accuracy: 0.3066 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5553 - accuracy: 0.2946 - val_loss: 1.5402 - val_accuracy: 0.3016 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5516 - accuracy: 0.2922 - val_loss: 1.5404 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5537 - accuracy: 0.2964 - val_loss: 1.5386 - val_accuracy: 0.3107 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5516 - accuracy: 0.3037 - val_loss: 1.5383 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5517 - accuracy: 0.2957 - val_loss: 1.5380 - val_accuracy: 0.3066 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5511 - accuracy: 0.2961 - val_loss: 1.5371 - val_accuracy: 0.3132 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5513 - accuracy: 0.3009 - val_loss: 1.5404 - val_accuracy: 0.3074 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5499 - accuracy: 0.3005 - val_loss: 1.5374 - val_accuracy: 0.3066 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5514 - accuracy: 0.2990 - val_loss: 1.5392 - val_accuracy: 0.3053 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5491 - accuracy: 0.2984 - val_loss: 1.5397 - val_accuracy: 0.3066 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5512 - accuracy: 0.3008 - val_loss: 1.5367 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5499 - accuracy: 0.2950 - val_loss: 1.5364 - val_accuracy: 0.3099 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5505 - accuracy: 0.2997 - val_loss: 1.5399 - val_accuracy: 0.3074 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5502 - accuracy: 0.2994 - val_loss: 1.5417 - val_accuracy: 0.3028 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5483 - accuracy: 0.2993 - val_loss: 1.5377 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5497 - accuracy: 0.3008 - val_loss: 1.5390 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5483 - accuracy: 0.2995 - val_loss: 1.5381 - val_accuracy: 0.3107 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5495 - accuracy: 0.3027 - val_loss: 1.5360 - val_accuracy: 0.3136 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5465 - accuracy: 0.3038 - val_loss: 1.5410 - val_accuracy: 0.3132 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5502 - accuracy: 0.3020 - val_loss: 1.5410 - val_accuracy: 0.3070 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5492 - accuracy: 0.2976 - val_loss: 1.5400 - val_accuracy: 0.3145 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5506 - accuracy: 0.2948 - val_loss: 1.5389 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5490 - accuracy: 0.3009 - val_loss: 1.5362 - val_accuracy: 0.3087 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5494 - accuracy: 0.3031 - val_loss: 1.5403 - val_accuracy: 0.3120 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5494 - accuracy: 0.2990 - val_loss: 1.5366 - val_accuracy: 0.3153 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5476 - accuracy: 0.2986 - val_loss: 1.5403 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5485 - accuracy: 0.3016 - val_loss: 1.5358 - val_accuracy: 0.3124 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5476 - accuracy: 0.3000 - val_loss: 1.5391 - val_accuracy: 0.3074 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5478 - accuracy: 0.3008 - val_loss: 1.5397 - val_accuracy: 0.3111 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5477 - accuracy: 0.3036 - val_loss: 1.5377 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5479 - accuracy: 0.3016 - val_loss: 1.5387 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5494 - accuracy: 0.3008 - val_loss: 1.5390 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5468 - accuracy: 0.3009 - val_loss: 1.5364 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5496 - accuracy: 0.2993 - val_loss: 1.5398 - val_accuracy: 0.3037 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5455 - accuracy: 0.2998 - val_loss: 1.5365 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5483 - accuracy: 0.2969 - val_loss: 1.5443 - val_accuracy: 0.3136 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5491 - accuracy: 0.3034 - val_loss: 1.5384 - val_accuracy: 0.3087 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5478 - accuracy: 0.3002 - val_loss: 1.5370 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5476 - accuracy: 0.3005 - val_loss: 1.5408 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5462 - accuracy: 0.3000 - val_loss: 1.5380 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5471 - accuracy: 0.3001 - val_loss: 1.5369 - val_accuracy: 0.3153 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5492 - accuracy: 0.2962 - val_loss: 1.5411 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5508 - accuracy: 0.2984 - val_loss: 1.5373 - val_accuracy: 0.3124 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5487 - accuracy: 0.2980 - val_loss: 1.5357 - val_accuracy: 0.3107 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5469 - accuracy: 0.3016 - val_loss: 1.5377 - val_accuracy: 0.3116 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5475 - accuracy: 0.3022 - val_loss: 1.5396 - val_accuracy: 0.3087 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5459 - accuracy: 0.2995 - val_loss: 1.5386 - val_accuracy: 0.3099 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5491 - accuracy: 0.2990 - val_loss: 1.5382 - val_accuracy: 0.3116 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5484 - accuracy: 0.3002 - val_loss: 1.5358 - val_accuracy: 0.3124 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5490 - accuracy: 0.3038 - val_loss: 1.5399 - val_accuracy: 0.3124 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5486 - accuracy: 0.2984 - val_loss: 1.5357 - val_accuracy: 0.3136 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5482 - accuracy: 0.3011 - val_loss: 1.5369 - val_accuracy: 0.3070 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5481 - accuracy: 0.3005 - val_loss: 1.5371 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5473 - accuracy: 0.3011 - val_loss: 1.5369 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5481 - accuracy: 0.2976 - val_loss: 1.5416 - val_accuracy: 0.3045 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5474 - accuracy: 0.3016 - val_loss: 1.5440 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5485 - accuracy: 0.2997 - val_loss: 1.5427 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5455 - accuracy: 0.2997 - val_loss: 1.5361 - val_accuracy: 0.3120 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5472 - accuracy: 0.2991 - val_loss: 1.5358 - val_accuracy: 0.3120 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5473 - accuracy: 0.3041 - val_loss: 1.5368 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5460 - accuracy: 0.2994 - val_loss: 1.5382 - val_accuracy: 0.3107 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5495 - accuracy: 0.3009 - val_loss: 1.5387 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5476 - accuracy: 0.2977 - val_loss: 1.5380 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5490 - accuracy: 0.2979 - val_loss: 1.5365 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5476 - accuracy: 0.2987 - val_loss: 1.5395 - val_accuracy: 0.3053 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5480 - accuracy: 0.3016 - val_loss: 1.5379 - val_accuracy: 0.3111 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5465 - accuracy: 0.3013 - val_loss: 1.5364 - val_accuracy: 0.3070 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5465 - accuracy: 0.2983 - val_loss: 1.5400 - val_accuracy: 0.3024 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5478 - accuracy: 0.3054 - val_loss: 1.5379 - val_accuracy: 0.3116 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5479 - accuracy: 0.3025 - val_loss: 1.5394 - val_accuracy: 0.3111 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5449 - accuracy: 0.2979 - val_loss: 1.5382 - val_accuracy: 0.3099 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5443 - accuracy: 0.3001 - val_loss: 1.5358 - val_accuracy: 0.3053 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5445 - accuracy: 0.3025 - val_loss: 1.5396 - val_accuracy: 0.3020 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5470 - accuracy: 0.3007 - val_loss: 1.5428 - val_accuracy: 0.3066 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5450 - accuracy: 0.3004 - val_loss: 1.5359 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5475 - accuracy: 0.3020 - val_loss: 1.5374 - val_accuracy: 0.3074 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5440 - accuracy: 0.3047 - val_loss: 1.5372 - val_accuracy: 0.3099 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5447 - accuracy: 0.3015 - val_loss: 1.5354 - val_accuracy: 0.3078 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5423 - accuracy: 0.2997 - val_loss: 1.5373 - val_accuracy: 0.3037 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5444 - accuracy: 0.3036 - val_loss: 1.5371 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5441 - accuracy: 0.3038 - val_loss: 1.5354 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5451 - accuracy: 0.3016 - val_loss: 1.5375 - val_accuracy: 0.3049 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5442 - accuracy: 0.2969 - val_loss: 1.5383 - val_accuracy: 0.3032 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5447 - accuracy: 0.3023 - val_loss: 1.5397 - val_accuracy: 0.2941 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5478 - accuracy: 0.3026 - val_loss: 1.5359 - val_accuracy: 0.3066 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5446 - accuracy: 0.3051 - val_loss: 1.5364 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5462 - accuracy: 0.3009 - val_loss: 1.5364 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5469 - accuracy: 0.3015 - val_loss: 1.5370 - val_accuracy: 0.3066 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5438 - accuracy: 0.3023 - val_loss: 1.5383 - val_accuracy: 0.3070 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5433 - accuracy: 0.3011 - val_loss: 1.5364 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5447 - accuracy: 0.3000 - val_loss: 1.5366 - val_accuracy: 0.3095 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5460 - accuracy: 0.3016 - val_loss: 1.5394 - val_accuracy: 0.3032 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5443 - accuracy: 0.2994 - val_loss: 1.5356 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5433 - accuracy: 0.2995 - val_loss: 1.5364 - val_accuracy: 0.3082 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5445 - accuracy: 0.2995 - val_loss: 1.5371 - val_accuracy: 0.3091 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5460 - accuracy: 0.2995 - val_loss: 1.5353 - val_accuracy: 0.3074 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 1.5443 - accuracy: 0.3015 - val_loss: 1.5354 - val_accuracy: 0.3049 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_zcr.h4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_zcr.h4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>Actual Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sad</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angry</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>angry</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>angry</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fear</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted Labels Actual Labels\n",
       "0              sad          fear\n",
       "1              sad          fear\n",
       "2            angry         happy\n",
       "3              sad           sad\n",
       "4              sad           sad\n",
       "5              sad         happy\n",
       "6            angry         angry\n",
       "7            angry         happy\n",
       "8            angry           sad\n",
       "9             fear         angry"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\"\"d=pd.read_csv(r\"C:\\Users\\dhanu\\Desktop\\Mini Project\\code_new\\chroma_stft.csv\")\n",
    "X = d.iloc[: ,:-1].values\n",
    "Y = d['label'].values\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\"\"\"\n",
    "print(x_train_zcr.shape, y_train.shape, x_test_zcr.shape, y_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train_zcr)\n",
    "x_test = scaler.transform(x_test_zcr)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.1)\n",
    "history_6=model.fit(x_train, y_train, batch_size=64, epochs=100, validation_data=(x_test, y_test), callbacks=[rlrp])\n",
    "model.save(\"cnn_zcr.h4\")\n",
    "pred_test_6 = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test_6)\n",
    "y_test_6 = encoder.inverse_transform(y_test)\n",
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test_6.flatten()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6528da7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "l_1 = history_1.history['accuracy']\n",
    "l_2 = history_2.history['accuracy']\n",
    "l_3 = history_3.history['accuracy']\n",
    "l_4 = history_4.history['accuracy']\n",
    "l_5 = history_5.history['accuracy']\n",
    "l_6 = history_5.history['accuracy']\n",
    "plt.rcParams['figure.figsize'] = [10, 9]\n",
    "epochs = range(0,100)\n",
    "plt.plot(epochs, l_1, 'b', label='all_features')\n",
    "plt.plot(epochs, l_2, 'g', label='mel')\n",
    "plt.plot(epochs, l_3, 'red', label='mfcc')\n",
    "plt.plot(epochs, l_4, 'yellow', label='rms')\n",
    "plt.plot(epochs, l_5, 'orange', label='chroma_stft')\n",
    "plt.plot(epochs, l_6, 'violet', label='zcr')\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "599880f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d17ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.76      0.30      0.43      1224\n",
      "     disgust       0.13      0.20      0.16       285\n",
      "        fear       0.03      0.26      0.06        61\n",
      "       happy       0.04      0.22      0.07        83\n",
      "         sad       0.56      0.36      0.44       751\n",
      "\n",
      "    accuracy                           0.30      2404\n",
      "   macro avg       0.30      0.27      0.23      2404\n",
      "weighted avg       0.58      0.30      0.38      2404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c06b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5b05f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"Predicted labels\":[\"sad\",\"disgust\",\"happy\",\"fear\",\"fear\"],\"Actual labels\":[\"sad\",\"fear\",\"happy\",\"fear\",\"sad\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e994fb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Actual labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predicted labels Actual labels\n",
       "0              sad           sad\n",
       "1          disgust          fear\n",
       "2            happy         happy\n",
       "3             fear          fear\n",
       "4             fear           sad"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a38c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values=[[\"MFCC\",0.7921,0.9752],[\"Mel\",0.4941,0.7440],[\"Chroma\",0.3818,.9171],[\"ZCR\",0.2721,0.3015],[\"RMS\",0.3463,0.3827],[\"Combining all features\",0.5707,0.9294]]\n",
    "columns=[\"Features\",\"LSTM\",\"CNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83624eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame(values,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cbb2a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>CNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MFCC</td>\n",
       "      <td>0.7921</td>\n",
       "      <td>0.9752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mel</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.7440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chroma</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.9171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZCR</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0.3015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RMS</td>\n",
       "      <td>0.3463</td>\n",
       "      <td>0.3827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combining all features</td>\n",
       "      <td>0.5707</td>\n",
       "      <td>0.9294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Features    LSTM     CNN\n",
       "0                    MFCC  0.7921  0.9752\n",
       "1                     Mel  0.4941  0.7440\n",
       "2                  Chroma  0.3818  0.9171\n",
       "3                     ZCR  0.2721  0.3015\n",
       "4                     RMS  0.3463  0.3827\n",
       "5  Combining all features  0.5707  0.9294"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f36b718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1add33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 6 artists>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(d.index,d[\"LSTM\"],color=\"purple\")\n",
    "plt.bar(d.index,d[\"CNN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26f558ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Grouped Bar Graph with dataframe'}, xlabel='Features'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "d.plot(x=\"Features\",\n",
    "        kind='bar',\n",
    "        stacked=False,\n",
    "        title='Grouped Bar Graph with dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2ccaa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Round 1  Round 2  Round 3  Round 4\n",
      "0    A       10       20       10       30\n",
      "1    B       20       25       15       25\n",
      "2    C       12       15       19        6\n",
      "3    D       10       29       13       19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Grouped Bar Graph with dataframe'}, xlabel='Team'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# importing package\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "  \n",
    "# create data\n",
    "df = pd.DataFrame([['A', 10, 20, 10, 30], ['B', 20, 25, 15, 25], ['C', 12, 15, 19, 6],\n",
    "                   ['D', 10, 29, 13, 19]],\n",
    "                  columns=['Team', 'Round 1', 'Round 2', 'Round 3', 'Round 4'])\n",
    "# view data\n",
    "print(df)\n",
    "  \n",
    "# plot grouped bar chart\n",
    "df.plot(x='Team',\n",
    "        kind='bar',\n",
    "        stacked=False,\n",
    "        title='Grouped Bar Graph with dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d6d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
